---
title: "Transforming Clinical Trials: Adaptive Approaches for Better Patient Outcomes"
date: 2024-05-27
categories: [Statistics]
tags: [Healthcare]
---

<script
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
  type="text/javascript">
</script>


## Introduction

Clinical trials have revolutionized healthcare, transforming human lives by enabling the development of new and effective treatments. These trials are the cornerstone of medical advancements, ensuring that new therapies are safe and effective before reaching the public. However, traditional clinical trials, characterized by fixed sample sizes, allocation, and entry criteria, often involve lengthy processes where data analysis occurs only after the trial's completion. This rigid approach, rooted in a 75-year-old design methodology, can lead to inefficiencies and ethical concerns, as it necessitates guessing at crucial parameters such as doses, patient populations, and treatment durations. Also a common "Theraputic misconception" exists among patients who are thinking about taking part in clinical trials. Trial participants and family members sometimes think that the purpose of a clinical trial is to improve their own outcomes. This misconception is frequently exacerbated by media advertisements for clinical research. Clinical trials primarily aim to evaluate the effect of a treatment on disease outcomes. Comparisons are typically made with standard care for conditions that have effective treatments and with placebo for conditions that do not yet have an established treatment. Any advantage received by a single trial participant is the result of randomization's chance effect combined with the actual, but unidentified, relative effects of the treatments. 

There is conflicting evidence currently available regarding the potential benefits that patients derive from merely taking part in clinical trials. Therefore, despite the fact that taking part in research is fundamentally an altruistic endeavor, many volunteers for clinical trials do not do so out of altruism. It is possible to raise the possibility that study participants will gain something from participating in a clinical trial by using an adaptive clinical trial design, which is topic of discussion of today's post. Obviously you don't want to end up like Mr. Hiram here!

<img src="/assets/images/AdaCT/placebo.jpg" alt = "AI">

## But what are adaptive clinical trials

Imagine you're playing a game where you have to guess how much candy is in a jar. In a traditional way, you'd guess once and wait until the end to see if you're right. But what if, during the game, you could get hints to adjust your guess as you go along? That’s kind of like how adaptive clinical trials work!

In regular clinical trials, scientists decide everything at the start and can't change anything until the end, which can take years. It's like making one big guess and sticking with it. But with adaptive clinical trials, scientists can make changes as they see how things are going. If they notice something isn't working well, they can try a different approach right away.

This way, they can find the best and safest treatments for patients faster. So, adaptive clinical trials are like getting helpful hints during the game, making it easier to win and making sure everyone has a better chance of getting the right amount of candy!

## Dynamic Treatment Allocation

Randomization is crucial in clinical trials to provide an unbiased comparison between new and standard therapies by balancing both measured and unmeasured covariates. Most trials use a 1:1 randomization scheme, which is suitable given the initial state of clinical equipoise. However, many participants are uncomfortable with random treatment assignment and would prefer a new treatment or an expert's decision.

As the trial progresses, knowledge about the treatments' effectiveness accumulates, but fixed assignment ignores this information, potentially leading to some patients receiving inferior therapy. While the primary goal of the trial should not be compromised, using interim data could improve outcomes for participants, especially those enrolling later, by increasing the likelihood of receiving the better treatment.

Adaptive clinical trials address this issue by allowing adjustments to key characteristics—such as randomization ratio and interim analysis frequency—based on accumulating data and pre-defined decision rules. This approach requires extensive numerical simulation to maintain statistical validity and control the false-positive rate.

## An adaptive randomisation trial

[Giles et al.](https://ascopubs.org/doi/10.1200/JCO.2003.11.016) conducted a randomized trial comparing three induction therapies for elderly patients with previously untreated, adverse karyotype acute myeloid leukemia. The standard regimen of idarubicin and ara-C (IA) was compared against two experimental regimens involving troxacitabine with either idarubicin (TI) or ara-C (TA). The primary endpoint was achieving complete remission (CR) without non-hematological grade 4 toxicities within 50 days; In other, words patients got better. If this is overwhelming, just remember that there were three treatments arms IA (Standard of Care), TI & TA (which were compared with Standard of Care)

Initially, patients were equally randomized to the three arms, but the trial used a response-adaptive randomization (RAR) scheme. This allowed for adjusting the randomization probabilities based on outcomes, favoring more promising arms and potentially dropping poorly performing ones. The probability of randomizing to IA was kept at 1/3 as long as all three arms were active.

After 24 patients were randomized, TI showed poor results, with a randomization probability dropping to just over 7%, leading to its termination. The trial was stopped after 34 patients when TA's randomization probability fell to 4%. The final success rates were 10/18 (56%) for IA, 3/11 (27%) for TA, and 0/5 (0%) for TI. Due to the RAR design, more than half of the patients (18/34) received the standard IA treatment, which proved to be the most effective. The trial concluded with fewer patients (34) than the planned maximum of 75, though it was noted that recruitment might have been stopped even earlier based on the observed outcomes. If this was traditional randomised clinical trial, we'd have more patients in the inferior arm than what we had in this one! 

<img src="/assets/images/AdaCT/trialprob.png" alt = "AI">
*Overview of this trial using a response-adaptive randomisation design. The probabilities shown are those at the time the patient on the $$x$$-axis was randomised. Coloured numbers indicate the arms to which the patients were randomised*



